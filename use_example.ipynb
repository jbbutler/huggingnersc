{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc255720-0ff0-4499-ad7c-e4ad56d0b5fa",
   "metadata": {},
   "source": [
    "# HuggingNERSCDataset API Use Example\n",
    "\n",
    "How to use the HuggingNERSCDataset API to catalog datasets on the NERSC HuggingFace organization, and link to locations in the NERSC CFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a34b0690-e88c-416b-85d4-7f75574b14c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingnersc_dataset import HuggingNERSCDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91ee401-fa04-4066-a999-89dca73f3641",
   "metadata": {},
   "source": [
    "## 1. Make a HuggingNERSCDataset object\n",
    "\n",
    "Supply an official name to give the dataset (to be displayed on webpages, notebooks, etc.) and a nickname (to be used in directory names, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "742b64de-90b3-4abd-ab88-c00cbd3a85c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "official_name = 'Iris'\n",
    "nickname = 'iris'\n",
    "\n",
    "hn_iris = HuggingNERSCDataset(official_name, nickname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d94c34e7-9a96-4278-8264-2ac888f88855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NERSC HuggingFace Dataset Object: \n",
       "        \n",
       " -official_name: Iris \n",
       "        \n",
       " -nickname: iris\n",
       "        \n",
       " -huggingface location: https://huggingface.co/datasets/NERSC/iris/\n",
       "        \n",
       " -nersc location: /global/cfs/cdirs/dasrepo/ai_ready_datasets/iris/"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39c1699-3751-4864-8134-e3943443c605",
   "metadata": {},
   "source": [
    "*Note: the above locations are not active until the directories in the local and huggingface NERSC repos are created*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096eda1e-6a8e-43da-964c-30131e641f6f",
   "metadata": {},
   "source": [
    "## 2. Make the directories in the NERSC CFS and Huggingface repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a503d1d8-e8e7-4efa-b59e-c85a62260ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/j/jbbutler/.conda/envs/das-internship/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "hn_iris.construct_repos()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed048ed-7b8c-4c3c-8a11-8d75a10c87f4",
   "metadata": {},
   "source": [
    "Repos will now be created at both of the locations described above. However, they will be empty. Next, we add a Jupyter notebook that can load the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51b4d99-3a7f-4de9-a755-f644b0d2a7fd",
   "metadata": {},
   "source": [
    "## 3. Construct loader notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a146685e-ce77-4cae-a5d5-a53e1364b6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "hn_iris.construct_notebook('iris.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a325e93-ff50-4b87-a872-3ef440968975",
   "metadata": {},
   "source": [
    "You should now have a loader notebook in the CFS repository for your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afbed0f-a4f6-4325-a7ab-f5b83085d01a",
   "metadata": {},
   "source": [
    "## 4. Fill Huggingface README\n",
    "\n",
    "Lastly, we want to populate the Huggingface README with all of our desired metadata. This will make it easier to search for datasets within the organization. This step also populates the readme with the loader code, as well as a link to the loader notebook we just created on the CFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f005680-0ff6-455f-bf70-311e3857f6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_readme = {'language':'en', \n",
    "                   'filename':'iris.csv', \n",
    "                   'tags':['pandas', 'csv', 'tabular'], \n",
    "                   'official_name':'Iris',\n",
    "                   'nickname':'iris',\n",
    "                   'size_bucket': 'n<1K'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d69abc76-81e4-4655-8e44-0b790d540687",
   "metadata": {},
   "outputs": [],
   "source": [
    "hn_iris.upload_readme(metadata_readme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408237bd-ebd0-4744-9720-abe7abbd8e96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "das-internship",
   "language": "python",
   "name": "das-internship"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
